{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Analysis\n",
    "\n",
    "##### The purpose of this notebook is to conduct tf-idf analysis to determine what terms appear most frequently for each candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in master dataframe and separate into two dataframes, one for each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_queries_with_data.csv',index_col=False)\n",
    "bf = df[df.city=='Boston']\n",
    "nf = df[df.city=='NYC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Source</th>\n",
       "      <th>Date Added</th>\n",
       "      <th>(Num Occurances)</th>\n",
       "      <th>city</th>\n",
       "      <th>seed_query</th>\n",
       "      <th>candidate</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jon santiago races 2021</td>\n",
       "      <td>autocomplete</td>\n",
       "      <td>2021-04-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston</td>\n",
       "      <td>jon santiago race</td>\n",
       "      <td>jon santiago</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>john barros wiki</td>\n",
       "      <td>autocomplete</td>\n",
       "      <td>2021-04-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston</td>\n",
       "      <td>john barros</td>\n",
       "      <td>john barros</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>boston mayoral election 2017</td>\n",
       "      <td>autocomplete</td>\n",
       "      <td>2021-04-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>michelle wu for mayor</td>\n",
       "      <td>autocomplete</td>\n",
       "      <td>2021-04-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston</td>\n",
       "      <td>michelle wu for mayor</td>\n",
       "      <td>michelle wu</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>john barros mayor elections 2018</td>\n",
       "      <td>autocomplete</td>\n",
       "      <td>2021-04-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston</td>\n",
       "      <td>john barros</td>\n",
       "      <td>john barros</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Query        Source  Date Added  \\\n",
       "0            jon santiago races 2021  autocomplete  2021-04-27   \n",
       "2                   john barros wiki  autocomplete  2021-04-27   \n",
       "6       boston mayoral election 2017  autocomplete  2021-04-27   \n",
       "26             michelle wu for mayor  autocomplete  2021-04-27   \n",
       "31  john barros mayor elections 2018  autocomplete  2021-04-27   \n",
       "\n",
       "    (Num Occurances)    city             seed_query     candidate gender  \n",
       "0                NaN  Boston      jon santiago race  jon santiago      M  \n",
       "2                NaN  Boston            john barros   john barros      M  \n",
       "6                NaN  Boston                    NaN           NaN    NaN  \n",
       "26               NaN  Boston  michelle wu for mayor   michelle wu      W  \n",
       "31               NaN  Boston            john barros   john barros      M  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions to calculate tf-idf from Eni's 315 notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf-idf\n",
    "def tf(term, doc, normalize=True):\n",
    "    \"\"\"Helper function to calculate term frequency.\n",
    "    \"\"\"\n",
    "    doc = doc.lower().split()\n",
    "    term = term.lower()\n",
    "    if normalize:\n",
    "        return doc.count(term) / float(len(doc))\n",
    "    else:\n",
    "        return doc.count(term) / 1.0\n",
    "    \n",
    "# Test the function\n",
    "\n",
    "#print(tf('the', corpus['a']))\n",
    "#print(tf('the', corpus['a'], False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def idf(term, corpus):\n",
    "    \"\"\"Helper function to calculate inverse document frequency.\n",
    "    \"\"\"\n",
    "    # Find all queries that contain the term\n",
    "    num_docs_with_term = len([True for candidate_queries in corpus if term.lower() in candidate_queries.lower()])\n",
    "\n",
    "    # tf-idf calc involves multiplying against a tf value less than 0, so it's\n",
    "    # necessary to return a value greater than 1 for consistent scoring.\n",
    "    # (Multiplying two values less than 1 returns a value less than each of\n",
    "    # them.)\n",
    "\n",
    "    try:\n",
    "        return 1.0 + log(float(len(corpus)) / num_docs_with_term)\n",
    "    except ZeroDivisionError:\n",
    "        return 1.0\n",
    " \n",
    "# Testing the function\n",
    "#print(idf('the', corpus.values()))\n",
    "#print(idf('a', corpus.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(term, doc, corpus):\n",
    "    \"\"\"Helper function to calculate tf-idf score.\"\"\"\n",
    "    return tf(term, doc) * idf(term, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our documents in this case will be a long string that is all the queries about that candidates joined together with a space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_candidate_docs(df, candidate):\n",
    "    '''takes dataframe and candidate, returns list of queries about that candidate combined into one long string'''\n",
    "    cand_queries = df[df['candidate']==candidate]['Query']\n",
    "    \n",
    "    return ' '.join(cand_queries)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the documents\n",
    "\n",
    "boston = {}\n",
    "for candidate in bf.candidate.unique():\n",
    "    #we need to ignore the case of the nan, which is from queries that aren't about a candidate, like 'nyc mayoral election'\n",
    "    if str(candidate) == 'nan': continue\n",
    "    boston[candidate] = make_candidate_docs(bf, candidate)\n",
    "\n",
    "nyc = {}\n",
    "for candidate in nf.candidate.unique():\n",
    "    if str(candidate) == 'nan': continue\n",
    "    nyc[candidate] = make_candidate_docs(nf, candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jon santiago races 2021 dr jon santiago massachusetts jon santiago campaign manager jon santiago mayoral election 2019 candidates jon santiago covid 1'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston['jon santiago'][:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'andrew yang twitter chicken soup andrew yang policies andrew yang early childhood education andrew yang education net worth andrew yang mayor new york'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc['andrew yang'][:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to make the corpus. This will be all the queries for each city combined into one long string. We want this to be city-specific in case there is some difference between city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the corpus will be all the queries for each city combined\n",
    "def make_corpus(city):\n",
    "    '''takes a city and returns a list of queries from candidates in city, each as one big string'''\n",
    "    if city== 'Boston': df = bf\n",
    "    else: df = nf\n",
    "    doc_list = []\n",
    "    city = df[df.city==city]\n",
    "    for candidate in city.candidate.unique():\n",
    "        doc_list.append(' '.join(city[city.candidate==candidate]['Query']))\n",
    "    \n",
    "    return doc_list\n",
    "\n",
    "bos_corpus = make_corpus('Boston')\n",
    "nyc_corpus = make_corpus('NYC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jon santiago races 2021 dr jon santiago massachusetts jon santiago campaign manager jon santiago mayoral election 2019 candidates jon santiago covid 19 dr jon santiago boston medical center jon santiago endorsements jon santiago nationality jon santi'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_corpus[0][:250]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The terms that we want to search are going to be unigrams from all queries, so that we can give all a fair chance and see which ones show up the most, not just looking for gendered words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a list of unigrams \n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stop = set(stopwords.words('english') + list(string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jon santiago isaac wright jr john barros scott stringer art chang andrew yang curtis sliwa aaron foldenauer eric adams ray mcguire dianne morales kathryn garcia michelle wu shaun donovan annisa essaibi george dana depelteau andrea campbell paperboy prince kim janey michael bianchi maya wiley fernando mateo isaac wright jr.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we want to filter out unigrams that are part of candidate names, since these will likely be top queries for almost all cands\n",
    "#let's make simple string of all candidate names so we can easily check if a unigram is inside it\n",
    "import numpy as np\n",
    "cand_names = list(df.candidate.unique())\n",
    "cand_names.append('isaac wright jr.') #some queries have a period in his name, so we want to exclude that\n",
    "cand_names.remove(np.nan)\n",
    "cand_names = ' '.join(cand_names)\n",
    "cand_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's generate all unigrams from the corpus. We want to exclude all unigrams that are just numbers and that are not part of a candidates name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_unigrams(corpus):\n",
    "    all_docs= ' '.join(corpus)\n",
    "  #  [all_docs.extend(doc) for doc in corpus]\n",
    "    unigrams = set(word_tokenize(all_docs))\n",
    "    return [i for i in unigrams if i not in stop and not i.isnumeric() and i.lower() not in cand_names] #there are some that are just years\n",
    "\n",
    "bos_unigrams = make_unigrams(bos_corpus)\n",
    "nyc_unigrams = make_unigrams(nyc_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['worth', 'summary', 'mattapan', 'deal', 'district', 'speech', 'sign', 'manager', 'partnerships', 'endorsements']\n",
      "['worth', 'images', 'summary', '3rd', 'bitcoin', 'district', 'resigned', 'funds', 'pba', 'stepfather']\n"
     ]
    }
   ],
   "source": [
    "print(bos_unigrams[:10])\n",
    "print(nyc_unigrams[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444\n",
      "842\n"
     ]
    }
   ],
   "source": [
    "print(len(bos_unigrams))\n",
    "print(len(nyc_unigrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Final calculations: Boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate all the final tf-idf scores, we'll iterate through all the candidates and then calculate the tf-idf scores for each unigram in that city's corpus, storing all information in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_dct = {}\n",
    "for candidate in bf.candidate.unique():\n",
    "    if str(candidate) == 'nan': continue\n",
    "    bos_dct[candidate] = []\n",
    "    for term in bos_unigrams:\n",
    "        bos_dct[candidate].append(tf_idf(term, boston[candidate], bos_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can store this in a dataframe for further analysis, the candidates will be the columns and the terms will be the first column, then the values in each cell the tf-idf score for that term for that candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['term']\n",
    "columns.extend(list(bos_dct.keys()))\n",
    "\n",
    "bos_dct['term'] = bos_unigrams\n",
    "bos_tfidf = pd.DataFrame(bos_dct,columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>jon santiago</th>\n",
       "      <th>john barros</th>\n",
       "      <th>michelle wu</th>\n",
       "      <th>annisa essaibi george</th>\n",
       "      <th>dana depelteau</th>\n",
       "      <th>andrea campbell</th>\n",
       "      <th>kim janey</th>\n",
       "      <th>michael bianchi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>worth</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>0.011291</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.009371</td>\n",
       "      <td>0.000697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>summary</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mattapan</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deal</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>district</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>wikipedia</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063423</td>\n",
       "      <td>0.009660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021055</td>\n",
       "      <td>0.012035</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>texas</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>ballotpedia</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>views</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045802</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>wunderlich</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>444 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            term  jon santiago  john barros  michelle wu  \\\n",
       "0          worth      0.000319     0.000258     0.002112   \n",
       "1        summary      0.000000     0.000000     0.000253   \n",
       "2       mattapan      0.000000     0.000000     0.000000   \n",
       "3           deal      0.000000     0.000000     0.000686   \n",
       "4       district      0.001118     0.000000     0.000000   \n",
       "..           ...           ...          ...          ...   \n",
       "439    wikipedia      0.000000     0.063423     0.009660   \n",
       "440        texas      0.000048     0.000000     0.000000   \n",
       "441  ballotpedia      0.000061     0.000000     0.000000   \n",
       "442        views      0.000000     0.000000     0.000000   \n",
       "443   wunderlich      0.000000     0.000000     0.000171   \n",
       "\n",
       "     annisa essaibi george  dana depelteau  andrea campbell  kim janey  \\\n",
       "0                 0.011291        0.001594         0.000523   0.009371   \n",
       "1                 0.000000        0.000066         0.000144   0.000000   \n",
       "2                 0.000000        0.000000         0.000088   0.000000   \n",
       "3                 0.000000        0.000000         0.000000   0.000000   \n",
       "4                 0.000000        0.000000         0.000058   0.000000   \n",
       "..                     ...             ...              ...        ...   \n",
       "439               0.000000        0.000000         0.021055   0.012035   \n",
       "440               0.000000        0.000159         0.000000   0.000000   \n",
       "441               0.000000        0.000000         0.000000   0.000000   \n",
       "442               0.000000        0.000000         0.000000   0.045802   \n",
       "443               0.000000        0.000000         0.000000   0.000000   \n",
       "\n",
       "     michael bianchi  \n",
       "0           0.000697  \n",
       "1           0.000000  \n",
       "2           0.000000  \n",
       "3           0.000000  \n",
       "4           0.015884  \n",
       "..               ...  \n",
       "439         0.000000  \n",
       "440         0.000000  \n",
       "441         0.000000  \n",
       "442         0.000000  \n",
       "443         0.000000  \n",
       "\n",
       "[444 rows x 9 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at which terms have the highest tf-idf scores for each candidate. We'll use the nlargest function in pandas to grab the 20 terms with the highest tf-idf scores for each candidate, storing this in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jon santiago  --> done!\n",
      "john barros  --> done!\n",
      "michelle wu  --> done!\n",
      "annisa essaibi george  --> done!\n",
      "dana depelteau  --> done!\n",
      "andrea campbell  --> done!\n",
      "kim janey  --> done!\n",
      "michael bianchi  --> done!\n"
     ]
    }
   ],
   "source": [
    "bos_top_dict = {} \n",
    "for candidate in bos_tfidf.columns[1:]:\n",
    "    mini = bos_tfidf.nlargest(20,candidate, 'all')\n",
    "    bos_top_dict[candidate] = mini['term'].unique()\n",
    "    print(candidate, ' --> done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jon santiago': array(['wife', 'alexandra', 'photographer', 'campaign', 'manager',\n",
       "        'endorsements', 'age', 'high', 'boston', 'mayor', 'md', 'school',\n",
       "        'globe', 'twitter', 'facebook', 'married', 'representative',\n",
       "        'state', 'instagram', 'medical'], dtype=object),\n",
       " 'john barros': array(['wife', 'boston', 'wikipedia', 'political', 'party', 'mayor',\n",
       "        'restaurant', 'bio', 'website', 'family', 'campaign', 'wiki',\n",
       "        'high', 'bc', 'age', 'manager', 'globe', 'barroso', 'twitter',\n",
       "        'massachusetts'], dtype=object),\n",
       " 'michelle wu': array(['husband', 'family', 'boston', 'mother', 'siblings', 'mayor',\n",
       "        'live', 'instagram', 'announcement', 'salary', 'accomplishments',\n",
       "        'child', 'collection', 'signature', 'campaign', 'care', 'policies',\n",
       "        'twitter', 'staff', 'events'], dtype=object),\n",
       " 'annisa essaibi george': array(['mayoral', 'election', 'race', 'elections', 'partnership',\n",
       "        'partners', 'worth', 'background', 'endorsement', 'COVID', 'LGBT',\n",
       "        'lgbt', 'mayor', 'mbta', 'transportation', 'partner', 'covid',\n",
       "        'boston', 'education', 'Education', 'net', 'MBTA'], dtype=object),\n",
       " 'dana depelteau': array(['tweets', 'black', 'matter', 'lives', 'twitter', 'mayor', 'boston',\n",
       "        'mayoral', 'linkedin', 'husband', 'election', 'police', 'crime',\n",
       "        'elections', 'hub', 'universal', 'candidates', 'scene', 'report',\n",
       "        'background'], dtype=object),\n",
       " 'andrea campbell': array(['brother', 'husband', 'twin', 'father', 'family', 'matthew',\n",
       "        'boston', 'bio', 'obituary', 'wikipedia', 'campaign', 'parents',\n",
       "        'events', 'fellowship', 'manager', 'endorsements', 'schools',\n",
       "        'plan', 'housing', 'jobs'], dtype=object),\n",
       " 'kim janey': array(['campaign', 'husband', 'mayor', 'views', 'political', 'daughter',\n",
       "        'age', 'website', 'family', 'headquarters', 'partner', 'parents',\n",
       "        'boston', 'married', 'nationality', 'manager', 'wikipedia',\n",
       "        'smith', 'worth', 'net'], dtype=object),\n",
       " 'michael bianchi': array(['brighton', 'boston', 'council', 'city', 'mayor', 'llc', 'actor',\n",
       "        'obituary', 'architect', 'bianchini', 'district', 'linkedin',\n",
       "        'bianchino', 'police', 'dds', 'omaha', 'report', 'nomura',\n",
       "        'housing', 'nj'], dtype=object)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_top_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Final calculations: NYC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is all the same as above, but just for NYC instead of Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_dct = {}\n",
    "for candidate in nf.candidate.unique():\n",
    "    if str(candidate) == 'nan': continue\n",
    "    nyc_dct[candidate] = []\n",
    "    for term in nyc_unigrams:\n",
    "        nyc_dct[candidate].append(tf_idf(term, nyc[candidate], nyc_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>isaac wright jr</th>\n",
       "      <th>scott stringer</th>\n",
       "      <th>art chang</th>\n",
       "      <th>andrew yang</th>\n",
       "      <th>curtis sliwa</th>\n",
       "      <th>aaron foldenauer</th>\n",
       "      <th>eric adams</th>\n",
       "      <th>ray mcguire</th>\n",
       "      <th>dianne morales</th>\n",
       "      <th>kathryn garcia</th>\n",
       "      <th>shaun donovan</th>\n",
       "      <th>paperboy prince</th>\n",
       "      <th>maya wiley</th>\n",
       "      <th>fernando mateo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>worth</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.002452</td>\n",
       "      <td>0.051808</td>\n",
       "      <td>0.031965</td>\n",
       "      <td>0.019089</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.008338</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.019004</td>\n",
       "      <td>0.023581</td>\n",
       "      <td>0.007239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images</td>\n",
       "      <td>0.002414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>summary</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3rd</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bitcoin</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>views</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.003823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>tucker</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>reopening</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>apk</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>true</td>\n",
       "      <td>0.008906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>842 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          term  isaac wright jr  scott stringer  art chang  andrew yang  \\\n",
       "0        worth         0.006847        0.001358   0.002452     0.051808   \n",
       "1       images         0.002414        0.000000   0.000000     0.000000   \n",
       "2      summary         0.000000        0.000000   0.000000     0.002531   \n",
       "3          3rd         0.000000        0.000000   0.000000     0.000000   \n",
       "4      bitcoin         0.000000        0.000000   0.000000     0.000000   \n",
       "..         ...              ...             ...        ...          ...   \n",
       "837      views         0.000000        0.000000   0.000000     0.000716   \n",
       "838     tucker         0.000000        0.000000   0.000000     0.000000   \n",
       "839  reopening         0.000000        0.000000   0.000000     0.001266   \n",
       "840        apk         0.000000        0.000000   0.025514     0.000000   \n",
       "841       true         0.008906        0.000000   0.000000     0.000000   \n",
       "\n",
       "     curtis sliwa  aaron foldenauer  eric adams  ray mcguire  dianne morales  \\\n",
       "0        0.031965          0.019089    0.002257     0.008338        0.001958   \n",
       "1        0.000000          0.000000    0.000000     0.000000        0.000000   \n",
       "2        0.000000          0.000000    0.000000     0.000000        0.000000   \n",
       "3        0.000000          0.000000    0.008317     0.000000        0.000000   \n",
       "4        0.000000          0.000000    0.009785     0.000000        0.000000   \n",
       "..            ...               ...         ...          ...             ...   \n",
       "837      0.000677          0.000000    0.006091     0.000000        0.000000   \n",
       "838      0.000000          0.000000    0.000070     0.000000        0.000000   \n",
       "839      0.000000          0.000000    0.000000     0.000000        0.000000   \n",
       "840      0.000000          0.000000    0.000000     0.000000        0.000000   \n",
       "841      0.000000          0.000000    0.000000     0.000000        0.000000   \n",
       "\n",
       "     kathryn garcia  shaun donovan  paperboy prince  maya wiley  \\\n",
       "0            0.0029       0.001947         0.019004    0.023581   \n",
       "1            0.0000       0.000000         0.000000    0.002771   \n",
       "2            0.0000       0.000000         0.000000    0.000000   \n",
       "3            0.0000       0.000000         0.000000    0.000000   \n",
       "4            0.0000       0.000000         0.000000    0.000000   \n",
       "..              ...            ...              ...         ...   \n",
       "837          0.0000       0.003823         0.000000    0.000000   \n",
       "838          0.0000       0.000000         0.000000    0.000000   \n",
       "839          0.0000       0.000000         0.000000    0.000000   \n",
       "840          0.0000       0.000000         0.000000    0.000000   \n",
       "841          0.0000       0.000000         0.000000    0.000000   \n",
       "\n",
       "     fernando mateo  \n",
       "0          0.007239  \n",
       "1          0.000000  \n",
       "2          0.000000  \n",
       "3          0.000000  \n",
       "4          0.000000  \n",
       "..              ...  \n",
       "837        0.004737  \n",
       "838        0.000000  \n",
       "839        0.000000  \n",
       "840        0.000000  \n",
       "841        0.000000  \n",
       "\n",
       "[842 rows x 15 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['term']\n",
    "columns.extend(list(nyc_dct.keys()))\n",
    "\n",
    "nyc_dct['term'] = nyc_unigrams\n",
    "nyc_tfidf = pd.DataFrame(nyc_dct,columns=columns)\n",
    "nyc_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'isaac wright jr': array(['wife', 'daughter', 'life', 'still', 'story', 'happened',\n",
       "        'settlement', 'lawyer', 'case', 'married', 'attorney', 'sunshine',\n",
       "        'prosecutor', 'friend', 'book', 'pictures', 'mayor', 'today',\n",
       "        'jamal', 'released', 'true'], dtype=object),\n",
       " 'scott stringer': array(['nyc', 'mayor', 'campaign', 'commercial', 'relations', 'york',\n",
       "        'new', 'news', 'kimball', 'jean', 'comptroller', 'jobs', 'wife',\n",
       "        'father', 'race', 'mother', 'married', 'kid', 'conference',\n",
       "        'ethnicity'], dtype=object),\n",
       " 'art chang': array(['changes', 'changer', 'everything', 'album', 'world', 'change',\n",
       "        'mayor', 'lives', 'morgan', 'changing', 'apk', 'elections',\n",
       "        'election', 'windows', 'jp', 'changed', 'nyc', 'driver', 'quotes',\n",
       "        'mayoral', 'race'], dtype=object),\n",
       " 'andrew yang': array(['mayor', 'worth', 'net', 'nyc', 'cartoon', 'wife', 'ubi', 'tweet',\n",
       "        'york', 'israel', 'new', 'basic', 'universal', 'income', 'reddit',\n",
       "        'twitter', 'education', 'debate', 'polls', 'news'], dtype=object),\n",
       " 'curtis sliwa': array(['trump', 'netflix', 'mayor', 'cats', 'nancy', 'regula', 'worth',\n",
       "        'net', 'platform', 'martial', 'wife', 'arts', 'parents',\n",
       "        'ethnicity', 'radio', 'guardian', 'angels', 'website', 'policies',\n",
       "        'debate'], dtype=object),\n",
       " 'aaron foldenauer': array(['mayoral', 'election', 'elections', 'tracks', 'council', 'worth',\n",
       "        'mayor', 'net', 'race', 'track', 'mtaca', 'attorney', 'firm',\n",
       "        'candidates', 'law', 'covid', 'nyc', 'forbes', 'chicago', 'mtac'],\n",
       "       dtype=object),\n",
       " 'eric adams': array(['wife', 'mayor', 'son', 'platform', 'partner', 'police', 'family',\n",
       "        'manowar', 'parents', 'education', 'policies', 'twitter', 'nyc',\n",
       "        'height', 'married', 'jordan', 'bitcoin', 'children', 'collins',\n",
       "        'salary'], dtype=object),\n",
       " 'ray mcguire': array(['mayor', 'citi', 'citigroup', 'nyc', 'york', 'new', 'wife',\n",
       "        'brooklyn', 'campaign', 'candidate', 'spike', 'check', 'son',\n",
       "        'basketball', 'compensation', 'lee', 'committee', 'house',\n",
       "        'website', 'worth', 'education', 'net'], dtype=object),\n",
       " 'dianne morales': array(['mayoral', 'nyc', 'campaign', 'mayor', 'union', 'staff', 'jobs',\n",
       "        'stuyvesant', 'election', 'phipps', 'implosion', 'polling',\n",
       "        'elections', 'high', 'nytimes', 'interview', 'endorsements',\n",
       "        'covid', 'twitter', 'charter', 'schools'], dtype=object),\n",
       " 'kathryn garcia': array(['mayor', 'nyc', 'endorsements', 'jerry', 'sanitation', 'dsny',\n",
       "        'times', 'mayoral', 'new', 'york', 'endorsement', 'nytimes',\n",
       "        'glass', 'food', 'commissioner', 'husband', 'education',\n",
       "        'election', 'latina', 'slope', 'park', 'department', 'hispanic'],\n",
       "       dtype=object),\n",
       " 'shaun donovan': array(['mayor', 'brooklyn', 'mayoral', 'house', 'interview', 'election',\n",
       "        'nyc', 'housing', 'home', 'prices', 'website', 'elections',\n",
       "        'campaign', 'jobs', 'pac', 'price', 'obama', 'father', 'cost',\n",
       "        'york', 'new'], dtype=object),\n",
       " 'paperboy prince': array(['results', 'mayor', 'election', 'suburbs', 'love', 'music',\n",
       "        'worth', 'mayoral', 'net', 'pronouns', 'rapper', 'gallery',\n",
       "        'vogue', 'stone', 'racers', 'rolling', 'mtaa', 'mtas', 'racer',\n",
       "        'congress'], dtype=object),\n",
       " 'maya wiley': array(['mayor', 'husband', 'endorsements', 'worth', 'net', 'nyc', 'new',\n",
       "        'york', 'harlan', 'mandel', 'aoc', 'mayoral', 'msnbc', 'endorses',\n",
       "        'daughters', 'photos', 'campaign', 'contact', 'running',\n",
       "        'daughter'], dtype=object),\n",
       " 'fernando mateo': array(['mayor', 'election', 'mayoral', 'elections', 'bodega', 'irvington',\n",
       "        'driver', 'restaurant', 'race', 'car', 'new', 'results', 'chicago',\n",
       "        'bronx', 'cuba', 'zona', 'tlc', 'mtab', 'government', 'mtabs',\n",
       "        'ny1', 'association', 'taxi', 'toilet', 'drivers', 'biografía',\n",
       "        'dominican', 'environment'], dtype=object)}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_top_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
